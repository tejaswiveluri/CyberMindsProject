{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9043ee33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishnaviet/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     /Users/vaishnaviet/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.79      0.86      0.82      1006\n",
      "        male       0.72      0.60      0.65       583\n",
      "\n",
      "    accuracy                           0.77      1589\n",
      "   macro avg       0.75      0.73      0.74      1589\n",
      "weighted avg       0.76      0.77      0.76      1589\n",
      "\n",
      "Accuracy: 0.7658904971680303\n",
      "\n",
      "Random Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.80      0.85      0.83      1006\n",
      "        male       0.71      0.63      0.67       583\n",
      "\n",
      "    accuracy                           0.77      1589\n",
      "   macro avg       0.76      0.74      0.75      1589\n",
      "weighted avg       0.77      0.77      0.77      1589\n",
      "\n",
      "Accuracy: 0.7715544367526747\n",
      "\n",
      "Decision Tree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.77      0.80      0.79      1006\n",
      "        male       0.64      0.59      0.61       583\n",
      "\n",
      "    accuracy                           0.73      1589\n",
      "   macro avg       0.70      0.70      0.70      1589\n",
      "weighted avg       0.72      0.73      0.72      1589\n",
      "\n",
      "Accuracy: 0.7262429200755192\n",
      "\n",
      "KNN:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.78      0.87      0.82      1006\n",
      "        male       0.72      0.58      0.64       583\n",
      "\n",
      "    accuracy                           0.76      1589\n",
      "   macro avg       0.75      0.72      0.73      1589\n",
      "weighted avg       0.76      0.76      0.76      1589\n",
      "\n",
      "Accuracy: 0.7627438640654499\n",
      "\n",
      "Gaussian Naive Bayes:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.67      0.95      0.79      1006\n",
      "        male       0.69      0.20      0.31       583\n",
      "\n",
      "    accuracy                           0.67      1589\n",
      "   macro avg       0.68      0.57      0.55      1589\n",
      "weighted avg       0.68      0.67      0.61      1589\n",
      "\n",
      "Accuracy: 0.6727501573316551\n",
      "\n",
      "Multinomial Naive Bayes:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.76      0.85      0.80      1006\n",
      "        male       0.68      0.54      0.60       583\n",
      "\n",
      "    accuracy                           0.74      1589\n",
      "   macro avg       0.72      0.70      0.70      1589\n",
      "weighted avg       0.73      0.74      0.73      1589\n",
      "\n",
      "Accuracy: 0.7382001258653241\n",
      "\n",
      "Bernoulli Naive Bayes:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.77      0.85      0.80      1006\n",
      "        male       0.68      0.55      0.61       583\n",
      "\n",
      "    accuracy                           0.74      1589\n",
      "   macro avg       0.72      0.70      0.71      1589\n",
      "weighted avg       0.73      0.74      0.73      1589\n",
      "\n",
      "Accuracy: 0.7388294524858402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from nltk.corpus import names\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "nltk.download('names')\n",
    "\n",
    "male_names = [(name, 'male') for name in names.words('male.txt')]\n",
    "female_names = [(name, 'female') for name in names.words('female.txt')]\n",
    "\n",
    "all_names = male_names + female_names\n",
    "random.shuffle(all_names)\n",
    "\n",
    "X = [name for name, _ in all_names]\n",
    "y = [gender for _, gender in all_names]\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2))\n",
    "X_transformed = vectorizer.fit_transform(X).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Bernoulli Naive Bayes': BernoulliNB()\n",
    "}\n",
    "\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{classifier_name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Accuracy: {accuracy}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b4f03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
